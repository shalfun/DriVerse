PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True CUDA_VISIBLE_DEVICES="0,1,2,3,4,5,6,7" MASTER_ADDR="0.0.0.0" MASTER_PORT='8044' WORD_SIZE=8 NODE_RANK=0 python \
  examples/wanvideo/train_wan_t2v_vae_control_wm.py \
  --task train \
  --train_architecture full  \
  --dataset_path /root/bos_folder/MIMO_WAN/MIMO_WAN/  \
  --text_encoder_path "/root/paddlejob/workspace/Wan2.1-I2V-14B-720P/models_t5_umt5-xxl-enc-bf16.pth" \
  --vae_path "/root/paddlejob/workspace/Wan2.1-I2V-14B-720P/Wan2.1_VAE.pth" \
  --clip_path "/root/paddlejob/workspace/Wan2.1-I2V-14B-720P/models_clip_open-clip-xlm-roberta-large-vit-huge-14.pth" \
  --output_path ckpts/fs0409/  \
  --dit_path "hybrid_control_dit.ckpt" \
  --steps_per_epoch 200   \
  --max_epochs 40  \
  --learning_rate 1e-5  \
  --accumulate_grad_batches 3  \
  --use_gradient_checkpointing \
  --height 480 \
  --width 832 \
  --num_nodes 1 \
  --use_gradient_checkpointing_offload \
  --training_strategy "deepspeed_stage_3" \
  --dataloader_num_workers 8 \
  --num_clips 797 \
